{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pygam import LogisticGAM\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "# Automating the proess of finding the filename\n",
    "dataFolder = 'data'\n",
    "plotsFolder = 'plots'\n",
    "state = 'TX'\n",
    "policeDept = 'statewide' # 'statewide' means state patrol\n",
    "\n",
    "# Choose column names to load\n",
    "colNamesList = ['date',\n",
    "                'time',\n",
    "                'location',\n",
    "                'lat',\n",
    "                'lng',\n",
    "                'county_name',\n",
    "#                 'district',\n",
    "#                 'precinct',\n",
    "#                 'region',\n",
    "                'subject_race',\n",
    "                'subject_sex',\n",
    "                'officer_id_hash',\n",
    "                'type',\n",
    "                'violation',\n",
    "                'citation_issued',\n",
    "                'warning_issued',\n",
    "                'outcome',\n",
    "                'contraband_found',\n",
    "                'contraband_drugs',\n",
    "                'contraband_weapons',\n",
    "                'search_conducted',\n",
    "                'search_vehicle',\n",
    "                'search_basis',\n",
    "                'vehicle_color',\n",
    "                'vehicle_make',\n",
    "                'vehicle_model',\n",
    "                'vehicle_type',\n",
    "                'vehicle_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automating the creation of rowName:dtype dict\n",
    "# This throws up a lot of stupid warnings/errors right now!\n",
    "# df = pd.read_csv(csvFilepath, nrows=5, names=colNamesList)\n",
    "# dtypeDict = df.dtypes.to_dict()\n",
    "# dtypeDict\n",
    "\n",
    "dtypeDict = {'raw_row_number': 'int64', \n",
    "             'date': 'object',\n",
    "             'time': 'object',\n",
    "             'location': 'object',\n",
    "             'lat': 'float64',\n",
    "             'lng': 'float64',\n",
    "             'county_name': 'object',\n",
    "             'district': 'object',\n",
    "             'precinct': 'object',\n",
    "             'region': 'float64',\n",
    "             'subject_race': 'object',\n",
    "             'subject_sex': 'object',\n",
    "             'officer_id_hash': 'object',\n",
    "             'type': 'object',\n",
    "             'violation': 'object',\n",
    "             'citation_issued': 'bool',\n",
    "             'warning_issued': 'bool',\n",
    "             'outcome': 'object',\n",
    "             'contraband_found': 'object',\n",
    "             'contraband_drugs': 'object',\n",
    "             'contraband_weapons': 'object',\n",
    "             'search_conducted': 'object',\n",
    "             'search_vehicle': 'object',\n",
    "             'search_basis': 'object',\n",
    "             'vehicle_color': 'object',\n",
    "             'vehicle_make': 'object',\n",
    "             'vehicle_model': 'object',\n",
    "             'vehicle_type': 'object',\n",
    "             'vehicle_year': 'float64',\n",
    "             'raw_HA_RACE_SEX': 'object',\n",
    "             'raw_HA_SEARCH_PC_boolean': 'object',\n",
    "             'raw_HA_SEARCH_CONCENT_boolean': 'object',\n",
    "             'raw_HA_INCIDTO_ARREST_boolean': 'object',\n",
    "             'raw_HA_VEHICLE_INVENT_boolean': 'object'}\n",
    "\n",
    "\n",
    "        \n",
    "# search_vehicle only has False and nan\n",
    "# type is just vehicular\n",
    "# violation column is of interest - reason for stop (split by |?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.load_data(dataFolder, state, policeDept, dtypeDict=dtypeDict, colNames=colNamesList)\n",
    "df = utils.remove_empty_rows(df, 'subject_race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df['subject_race']).reshape(-1,1)\n",
    "y = np.array(df['citation_issued']).astype(int)\n",
    "\n",
    "enc = OneHotEncoder(categories=[df['subject_race'].unique().tolist()])\n",
    "enc.fit(X)\n",
    "X = enc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22804625, 4) (22804625,) (4024346, 4) (4024346,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)\n",
    "X_train = X_train[:,1:]\n",
    "X_test = X_test[:,1:]\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with built-in Cross Validation\n",
    "l2 penalty and lbfgs solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6262521308725751"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "y_train_pred = clf.predict(X_train)\n",
    "np.mean(y_train_pred == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6260950226446732"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "y_test_pred = clf.predict(X_test)\n",
    "np.mean(y_test_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3167457 , 0.27873825, 0.25599212, 0.05141742]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.64852582])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['white', 'hispanic', 'black', 'asian/pacific islander', 'other'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.37265347, 1.32146141, 1.29174255, 1.05276225]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52281593])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with built-in Cross Validation\n",
    "l2 penalty and sag solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(random_state=0, solver='sag')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegressionCV(solver='sag', penalty='l2', random_state=0)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6262521308725751"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "y_train_pred = clf2.predict(X_train)\n",
    "np.mean(y_train_pred == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6260950226446732"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "y_test_pred = clf2.predict(X_test)\n",
    "np.mean(y_test_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21279648,  0.10758595,  0.07197385,  0.06741477, -0.03416888]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with built-in Cross Validation\n",
    "l1 penalty and saga solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(penalty='l1', random_state=0, solver='saga')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = LogisticRegressionCV(solver='saga', penalty='l1', random_state=0)\n",
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6262521308725751"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "y_train_pred = clf3.predict(X_train)\n",
    "np.mean(y_train_pred == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6260950226446732"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "y_test_pred = clf3.predict(X_test)\n",
    "np.mean(y_test_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28190316,  0.03056305,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitic Regression with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'], \n",
    "    'C': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1, 1e2, 1e3, 1e4], \n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "logreg = LogisticRegression(max_iter=400, random_state=0)\n",
    "clf1 = GridSearchCV(logreg, parameters)\n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training accuracy\n",
    "y_train_pred1 = clf1.predict(X_train)\n",
    "np.mean(y_train_pred1 == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "y_test_pred1 = clf1.predict(X_test)\n",
    "np.mean(y_test_pred1 == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic GAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "N/A% (0 of 11) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    }
   ],
   "source": [
    "gam = LogisticGAM().gridsearch(X_train.todense(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training accuracy\n",
    "y_train_pred2 = gam.predict(X_train)\n",
    "np.mean(y_train_pred2 == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "y_test_pred2 = gam.predict(X_test)\n",
    "np.mean(y_test_pred2 == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22804625x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 22804625 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
