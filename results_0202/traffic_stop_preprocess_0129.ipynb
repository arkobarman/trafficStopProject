{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys0LTg4l-P1v"
      },
      "source": [
        "This notebook preprocesses data and saves the preprocessed data to csv files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JhuEbDvDXZL",
        "outputId": "ec173356-cc9a-4c3f-9b9b-261c2fd4affc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os \n",
        "drive.mount('/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnx3erpE-LKT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import date, timedelta\n",
        "import datetime\n",
        "import holidays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqTh88StGem1"
      },
      "outputs": [],
      "source": [
        "def get_holiday(year):\n",
        "  # have a list of holidays\n",
        "  holiday_days = set()\n",
        "\n",
        "  # Print all the holidays in US in year 2016\n",
        "  for ptr in holidays.US(years = year).items():\n",
        "      #print(ptr[0], ptr[1])\n",
        "      holiday_days.add(ptr[0])\n",
        "\n",
        "  # further processing to include several days before and after\n",
        "\n",
        "  # christmas - new year \n",
        "  start_date = date(year, 12, 24) \n",
        "  end_date = date(year, 12, 31)  \n",
        "\n",
        "  delta = end_date - start_date   # returns timedelta\n",
        "\n",
        "  for i in range(delta.days + 1):\n",
        "      day = start_date + timedelta(days=i)\n",
        "      holiday_days.add(day)\n",
        "\n",
        "  # After new year -> until the first monday\n",
        "  # specify year and month\n",
        "  yearMonth = str(year) + '-01'\n",
        "  firstDay = str(year) + '-01-01'\n",
        "  firstDate = date(year,1,1)\n",
        "  # getting date of first monday\n",
        "  firstMonday = np.busday_offset(yearMonth, 0, \n",
        "                            roll='forward', \n",
        "                            weekmask='Mon')\n",
        "  # if firstDay is not Monday\n",
        "  if str(firstMonday) != firstDay:\n",
        "    start_date = date(year, 1, 1) \n",
        "    end_date = datetime.datetime.strptime(str(firstMonday),'%Y-%m-%d').date()-timedelta(days=1) \n",
        "\n",
        "    delta = end_date - start_date   # returns timedelta\n",
        "\n",
        "    for i in range(delta.days + 1):\n",
        "        day = start_date + timedelta(days=i)\n",
        "        holiday_days.add(day)\n",
        "\n",
        "  # if firstDay is Monday, only include that day-> already in the auto-generated holiday list\n",
        "\n",
        "  # july 4th: one week \n",
        "  indepDay = date(year,7,4)\n",
        "  prev_monday = indepDay + timedelta(days=-indepDay.weekday())\n",
        "  next_sunday = indepDay + timedelta(days=-(indepDay.weekday()+1), weeks=1)\n",
        "  delta = next_sunday - prev_monday   # returns timedelta\n",
        "  for i in range(delta.days + 1):\n",
        "    day = prev_monday + timedelta(days=i)\n",
        "    holiday_days.add(day)\n",
        "\n",
        "  return list(holiday_days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_wPhZSoezvs"
      },
      "outputs": [],
      "source": [
        "def is_holiday(year,row):\n",
        "\n",
        "  holiday_list = get_holiday(year)\n",
        "\n",
        "  dow = row['date'].weekday() \n",
        "  # 5 Sat, 6 Sun\n",
        "  if dow == 5 or dow == 6: \n",
        "    return 1\n",
        "  # Mon-Thursday\n",
        "  elif dow < 4:\n",
        "    if row['date'] not in holiday_list:\n",
        "      return 0\n",
        "    else:\n",
        "      return 1\n",
        "  # if Friday: after dusk, holiday = 1; before dusk, holiday list\n",
        "  else:\n",
        "    if row['light_cat'] == 'dark' or row['date'] in holiday_list:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS0PXwZjCG-b"
      },
      "outputs": [],
      "source": [
        "def remove_duplicates(row):\n",
        "  if row['speeding_only'] == 'speeding-repeated_entries':\n",
        "    return row['all_violation'][0].strip()\n",
        "  else:\n",
        "    return row['violation']\n",
        "\n",
        "def exclusive(vio_lst):\n",
        "  count = 0\n",
        "  for vio in vio_lst:\n",
        "    # count number of violations containing 'speed'\n",
        "    if 'speed' in vio:\n",
        "      count += 1\n",
        "  # if only 1 speeding-related violation, return 1\n",
        "  # if all of the violations (for this record) include speeding and more than 1 violation, return 2\n",
        "  # if include violations other than speeding, return 3\n",
        "  if count == 1 and count == len(vio_lst):\n",
        "    return 'speeding-1'\n",
        "  elif count == len(vio_lst):\n",
        "    if len(vio_lst) == len(set(vio_lst)):\n",
        "      return 'speeding-repeated_entries'\n",
        "    return 'speeding-multiple'\n",
        "  elif count < len(vio_lst):\n",
        "    return 'speeding+others'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vslxjLBkB9KM"
      },
      "outputs": [],
      "source": [
        "def speeding_filter(df):\n",
        "  print('Before speed filtering: ', len(df))\n",
        "  df['violation'] = [s.lower() for s in df['violation']]\n",
        "  df = df.loc[df['violation'].str.contains('speed', regex = False),:]\n",
        "  df['violation'] = df['violation'].map(lambda x: x.replace('(#)',''))\n",
        "  df['violation'] = df['violation'].map(lambda x: x.strip())\n",
        "\n",
        "  # get a list of violations for each record, and apply self-defined func exclusive\n",
        "  df['all_violation'] = df['violation'].str.split('|')\n",
        "  df['speeding_only'] = df['all_violation'].map(lambda x: exclusive(x))\n",
        "\n",
        "  # filter out rows with violations other than speeding\n",
        "  df = df.loc[df['speeding_only'].isin(['speeding-repeated_entries','speeding-1'])]\n",
        "  # print('All single speeding violation records: ', len(df))\n",
        "  df['violation'] = df.apply(lambda row: remove_duplicates(row), axis = 1)\n",
        "\n",
        "  df = df.loc[~df['violation'].isin(['speeding-10% or more above posted speed','unsafe speed','fail to control speed','speeding cmv 15 mph or more over limit']),:]\n",
        "  # df.drop(['all_violation','speeding_only','violation'], axis = 1, inplace = True)\n",
        "  print('After speed filtering: ', len(df))\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76T2QJz5EWzc",
        "outputId": "5df0a4a3-f6b5-4fab-ca19-d9e44967448c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting astral\n",
            "  Downloading astral-2.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from astral) (2018.9)\n",
            "Installing collected packages: astral\n",
            "Successfully installed astral-2.2\n",
            "Collecting PyAstronomy\n",
            "  Downloading PyAstronomy-0.17.1.tar.gz (711 kB)\n",
            "\u001b[K     |████████████████████████████████| 711 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from PyAstronomy) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from PyAstronomy) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from PyAstronomy) (1.4.1)\n",
            "Collecting quantities\n",
            "  Downloading quantities-0.13.0.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting bidict\n",
            "  Downloading bidict-0.21.4-py3-none-any.whl (36 kB)\n",
            "Building wheels for collected packages: PyAstronomy, quantities\n",
            "  Building wheel for PyAstronomy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyAstronomy: filename=PyAstronomy-0.17.1-py3-none-any.whl size=504451 sha256=29d8f57517b308c86b483354b9d319d5b1ef3a22bd086561c080f0d2e227a26a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/3b/34/d1ade1c2c660da472dd7e441b19eaf1066cc778f65fdcec5d4\n",
            "  Building wheel for quantities (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for quantities: filename=quantities-0.13.0-py3-none-any.whl size=77860 sha256=cf238d39e75ce1eb9baeb7b4007a5616442c66224bcd5d6d9e2d5f304e5968f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/9d/0a/cbfeaa29541b7fc8752d35f368e63578a9f64229878841412a\n",
            "Successfully built PyAstronomy quantities\n",
            "Installing collected packages: quantities, bidict, PyAstronomy\n",
            "Successfully installed PyAstronomy-0.17.1 bidict-0.21.4 quantities-0.13.0\n"
          ]
        }
      ],
      "source": [
        "! pip install astral\n",
        "! pip install PyAstronomy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZVugSXA_kiP",
        "outputId": "4295ff82-b922-4219-d3d3-8f03ce729808"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ],
      "source": [
        "from PyAstronomy import pyasl\n",
        "from astral import LocationInfo\n",
        "from astral.sun import sun\n",
        "import pytz\n",
        "import datetime\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-6ttVx2eRaH"
      },
      "outputs": [],
      "source": [
        "def sunrise_sunset(row,info):\n",
        "  \"\"\"\n",
        "  lat and lnt: latitude and longitude, float\n",
        "  dat: datetime.date object\n",
        "  info: 'sunrise';'sunset';'dawn';'dusk'\n",
        "  return: return the datetime.datetime object for specified info type\n",
        "  \"\"\"\n",
        "  #sunrise_sunset(lat,lng,dat,rise_set)\n",
        "  lat = row['lat']\n",
        "  lng = row['lng']\n",
        "  dat = row['date']\n",
        "\n",
        "  # use central timezone, need to change for two counties!!!!\n",
        "  city = LocationInfo(timezone = 'US/Central', latitude = lat, longitude = lng)\n",
        "  s = sun(city.observer, date = dat, tzinfo = city.timezone)\n",
        "\n",
        "  # Get relevant info\n",
        "  if info == 'sunset':\n",
        "    # central time zone\n",
        "    sunset = s[\"sunset\"]\n",
        "    sunset = sunset.strftime('%Y:%m:%d:%H:%M:%S')\n",
        "    sunset = datetime.datetime.strptime(sunset, '%Y:%m:%d:%H:%M:%S')\n",
        "    return sunset\n",
        "   \n",
        "  if info == 'sunrise':\n",
        "    # central time zone\n",
        "    sunrise = s[\"sunrise\"]\n",
        "    sunrise = sunrise.strftime('%Y:%m:%d:%H:%M:%S')\n",
        "    sunrise = datetime.datetime.strptime(sunrise, '%Y:%m:%d:%H:%M:%S')\n",
        "    return sunrise\n",
        "    \n",
        "  if info == 'dawn':\n",
        "    # central time zone\n",
        "    dawn = s[\"dawn\"]\n",
        "    dawn = dawn.strftime('%Y:%m:%d:%H:%M:%S')\n",
        "    dawn = datetime.datetime.strptime(dawn, '%Y:%m:%d:%H:%M:%S')\n",
        "    return dawn\n",
        "\n",
        "  if info == 'dusk':\n",
        "    # central time zone\n",
        "    dusk = s[\"dusk\"]\n",
        "    dusk = dusk.strftime('%Y:%m:%d:%H:%M:%S')\n",
        "    dusk = datetime.datetime.strptime(dusk, '%Y:%m:%d:%H:%M:%S')\n",
        "    return dusk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIrbST8zRx6s"
      },
      "source": [
        "Split time of day into three categories:\n",
        "- Midnight to Before dawn = dark\n",
        "- dawn to 30 min after sunrise = half-light\n",
        "- 30 min after sunrise to 30 min before sunset = light\n",
        "- 30 min before sunset to dusk = half-light\n",
        "- Dusk to midnight = dark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "litLw30wTBnP"
      },
      "outputs": [],
      "source": [
        "def get_light_cat(row):\n",
        "  delta = datetime.timedelta(minutes = 30)\n",
        "  light_lower = row['sunrise'] + delta\n",
        "  light_higher = row['sunset'] - delta\n",
        "\n",
        "  if row['stop_time'] < row['dawn'] or row['stop_time'] > row['dusk']:\n",
        "    return 'dark'\n",
        "  if light_lower <= row['stop_time'] <= light_higher:\n",
        "    return 'light'\n",
        "  else:\n",
        "    return 'half_light'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7Q-tlPZmzqF"
      },
      "outputs": [],
      "source": [
        "def add_daylight(df):\n",
        "  \"\"\"\n",
        "  INPUT:\n",
        "  df: traffic stop dataframe\n",
        "  county_info: county->lat/lng dataframe\n",
        "  OUTPUT: \n",
        "  dataframe with a new column of daytime: 1 if daytime 0 if \n",
        "  NOTE:\n",
        "  if a row(records) does not have either county info or latitude/longitude info, it will be deleted\n",
        "  \"\"\"\n",
        "  # read in county_info\n",
        "  county_info = pd.read_csv('/gdrive/MyDrive/traffic_stop/table_county.csv')\n",
        "  \n",
        "  # preprocessing county_info dataframe\n",
        "  # minus sign, delete celsius sign\n",
        "  county_info['Longitude'] = county_info['Longitude'].map(lambda x: '-' + x[1:])\n",
        "  for col in ['Latitude','Longitude']:\n",
        "    county_info[col] = county_info[col].map(lambda x: x[:-1])\n",
        "    county_info[col] = county_info[col].astype('float')\n",
        "\n",
        "  # we are focusing on Texas\n",
        "  county_info = county_info.loc[county_info['State'] == 'TX',:]\n",
        "\n",
        "  # 1) select rows with missing values in latitude/longitude, but having county info -> needs processing\n",
        "  cols = ['lat','lng']\n",
        "  mask = df[cols].isna().any(axis=1)\n",
        "  df_c = df[mask]\n",
        "  df_c = df_c.loc[df_c['county_name'].notna(),:]\n",
        "\n",
        "  # 2) select rows with latitude & longitude values\n",
        "  df_complete = df.loc[(df['lat'].notna())&(df['lng'].notna())]\n",
        "\n",
        "  # make a 'new_county' column to correspond to the identifiers in the county_info csv\n",
        "  df_c['new_county'] = df_c['county_name'].map(lambda x: x.replace(' County', ''))\n",
        "  df_c['new_county'] = df_c['new_county'].replace('Dewitt','DeWitt')\n",
        "\n",
        "  # rename county info's column\n",
        "  county_info = county_info[['State','County [2]','Latitude','Longitude']]\n",
        "  county_info.rename(columns={\"County [2]\": \"county\"}, inplace = True)\n",
        "\n",
        "  # fill in missing latitude and longitude with county info\n",
        "  df_merged = df_c.merge(county_info, how = 'inner', left_on = 'new_county', right_on = 'county')\n",
        "  df_merged['lat'].fillna(df_merged['Latitude'], inplace = True)\n",
        "  df_merged['lng'].fillna(df_merged['Longitude'], inplace = True)\n",
        "\n",
        "  # merged the two dfs: 2) originally with lat/lng and 1) without but filled based on county info\n",
        "  df_merged.drop(['new_county','State','county','Latitude','Longitude'], axis = 1, inplace = True)\n",
        "  df = pd.concat([df_complete,df_merged], ignore_index=True)\n",
        "  \n",
        "  #for col in ['lat','lng']:\n",
        "    #df[col].astype('float')\n",
        "\n",
        "  # add 'sunrise', 'sunset', 'dawn', 'dusk' columns, data types are all datetime.datetime object\n",
        "  df['sunset'] = df.apply(lambda row: sunrise_sunset(row,'sunset'),axis=1)\n",
        "  df['sunrise'] = df.apply(lambda row: sunrise_sunset(row,'sunrise'),axis = 1)\n",
        "  df['dawn'] = df.apply(lambda row: sunrise_sunset(row,'dawn'),axis = 1)\n",
        "  df['dusk'] = df.apply(lambda row: sunrise_sunset(row,'dusk'),axis = 1)\n",
        "\n",
        "  # add 'stop_time' column \n",
        "  df['stop_time'] = df.apply(lambda row: datetime.datetime.combine(row['date'], row['time']), axis = 1)\n",
        "\n",
        "  # get stop time category\n",
        "  df['light_cat'] = df.apply(lambda row: get_light_cat(row), axis = 1)\n",
        " \n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCU6Z0BU4X6V"
      },
      "outputs": [],
      "source": [
        "keep_col = ['date', \n",
        "                'time', \n",
        "                'county_name', \n",
        "                'subject_race',\n",
        "                'subject_sex',\n",
        "                'violation', \n",
        "                'citation_issued',\n",
        "                'contraband_found',\n",
        "                'contraband_drugs',\n",
        "                'contraband_weapons',\n",
        "                'search_conducted',\n",
        "                'search_vehicle',\n",
        "                'lat',\n",
        "                'lng'\n",
        "                ]\n",
        "rm_na_col = ['county_name','violation','subject_race','subject_sex']\n",
        "\n",
        "def remove_empty_rows(df, colName):\n",
        "\tdf = df[df[colName] != 'unknown']\n",
        "\tdf = df[df[colName].notna()]\n",
        "\treturn(df)\n",
        "\n",
        "def preprocess(year, keep_col, rm_na_col, violation_type = None):\n",
        "  # read dataframe\n",
        "  filename = '/gdrive/MyDrive/traffic_stop/year_data/traffic_' + str(year) + '.parquet'\n",
        "  df = pd.read_parquet(filename, engine = 'pyarrow')\n",
        "\n",
        "  # invalid value\n",
        "  if year == 2013:\n",
        "    df.drop(df.index[df['lat'] == 74.052879], inplace=True)\n",
        "\n",
        "  ## drop unrelated columns\n",
        "  col_drop = [col for col in df.columns if col not in keep_col]\n",
        "  df.drop(col_drop, axis = 1, inplace = True)\n",
        "\n",
        "  # remove rows with missing values in rm_na_col\n",
        "  for col in rm_na_col:\n",
        "    df = remove_empty_rows(df, col)\n",
        "  \n",
        "  # filter speed only include single speed violation with low citation rate\n",
        "  df = speeding_filter(df)\n",
        "\n",
        "  ## County names are converted to county type - metropolitan, micropolitan or non-core\n",
        "  # For definitions, see US OMB website\n",
        "\n",
        "  # read in county info csv\n",
        "  county_df = pd.read_csv('/gdrive/MyDrive/traffic_stop/2014-2018.csv')\n",
        "  county_df = county_df[county_df['State']=='Texas']\n",
        "  county_df = county_df.filter(items=['Metropolitan Status', 'County Name'])\n",
        "\n",
        "  # transform column\n",
        "  df['county'] = [name[:-7] for name in df['county_name']]\n",
        "  df = df.join(county_df.set_index('County Name'), on='county')\n",
        "  df.drop('county', 1, inplace=True)\n",
        "  df.rename(columns={'Metropolitan Status':'county_type'}, inplace=True)\n",
        "\n",
        "  # !!! need to check where the missing values of county_type come from\n",
        "  df = df.loc[df['county_type'].notna(),:]\n",
        "\n",
        "  # Convert 'citation issued' to integer\n",
        "  df = df.astype({'citation_issued': 'int64'})\n",
        "\n",
        "  # search and contraband related variables have three levels: None, True, False, if not True, use 0, else 1\n",
        "  for col in ['contraband_found','contraband_drugs','contraband_weapons','search_conducted','search_vehicle']:\n",
        "    df[col] = df[col].map({True: 1, False: 0, None: 0})\n",
        "\n",
        "  # if race is other/unknown, we delete the rows!\n",
        "  df = df.loc[(df['subject_race'] != 'unknown') & (df['subject_race'] != 'other'),:]\n",
        "\n",
        "  # add lightning variable\n",
        "  df = add_daylight(df)\n",
        "  # add holiday variable\n",
        "  df['holiday'] = df.apply(lambda row: is_holiday(year, row), axis = 1)\n",
        "\n",
        "  # df.drop(['sunset','sunrise','dawn','dusk','stop_time','time','lat','lng','date','county_name'], axis = 1, inplace = True)\n",
        "  \n",
        "  # get dummies for race and sex\n",
        "  # df = pd.get_dummies(df)\n",
        " \n",
        "  # Base level: White, Male, Non_core (county type)\n",
        "  # df.drop(['subject_race_white', 'subject_sex_male', 'county_type_Non core','subject_race_other','subject_race_unknown'], axis = 1, inplace = True)\n",
        "  print(df.columns)\n",
        "  return df "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GSIMy9ljO50",
        "outputId": "00fae86f-5737-479a-f3d6-9e6289687da8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "years = []\n",
        "for i in range(2006, 2018):\n",
        "  years.append(i)\n",
        "years"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OARsLrBENBA"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hF0vg3WajMi-",
        "outputId": "1266e6e9-30cb-4ae3-f2ca-21f9158b29f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before speed filtering:  2673511\n",
            "After speed filtering:  767749\n",
            "Index(['date', 'time', 'lat', 'lng', 'county_name', 'subject_race',\n",
            "       'subject_sex', 'violation', 'citation_issued', 'contraband_found',\n",
            "       'contraband_drugs', 'contraband_weapons', 'search_conducted',\n",
            "       'search_vehicle', 'all_violation', 'speeding_only', 'county_type',\n",
            "       'sunset', 'sunrise', 'dawn', 'dusk', 'stop_time', 'light_cat',\n",
            "       'holiday'],\n",
            "      dtype='object')\n",
            "Before speed filtering:  2405744\n",
            "After speed filtering:  698046\n",
            "Index(['date', 'time', 'lat', 'lng', 'county_name', 'subject_race',\n",
            "       'subject_sex', 'violation', 'citation_issued', 'contraband_found',\n",
            "       'contraband_drugs', 'contraband_weapons', 'search_conducted',\n",
            "       'search_vehicle', 'all_violation', 'speeding_only', 'county_type',\n",
            "       'sunset', 'sunrise', 'dawn', 'dusk', 'stop_time', 'light_cat',\n",
            "       'holiday'],\n",
            "      dtype='object')\n",
            "Before speed filtering:  2434970\n",
            "After speed filtering:  764522\n",
            "Index(['date', 'time', 'lat', 'lng', 'county_name', 'subject_race',\n",
            "       'subject_sex', 'violation', 'citation_issued', 'contraband_found',\n",
            "       'contraband_drugs', 'contraband_weapons', 'search_conducted',\n",
            "       'search_vehicle', 'all_violation', 'speeding_only', 'county_type',\n",
            "       'sunset', 'sunrise', 'dawn', 'dusk', 'stop_time', 'light_cat',\n",
            "       'holiday'],\n",
            "      dtype='object')\n",
            "Before speed filtering:  2370986\n",
            "After speed filtering:  758925\n",
            "Index(['date', 'time', 'lat', 'lng', 'county_name', 'subject_race',\n",
            "       'subject_sex', 'violation', 'citation_issued', 'contraband_found',\n",
            "       'contraband_drugs', 'contraband_weapons', 'search_conducted',\n",
            "       'search_vehicle', 'all_violation', 'speeding_only', 'county_type',\n",
            "       'sunset', 'sunrise', 'dawn', 'dusk', 'stop_time', 'light_cat',\n",
            "       'holiday'],\n",
            "      dtype='object')\n",
            "Before speed filtering:  2452498\n",
            "After speed filtering:  782276\n",
            "Index(['date', 'time', 'lat', 'lng', 'county_name', 'subject_race',\n",
            "       'subject_sex', 'violation', 'citation_issued', 'contraband_found',\n",
            "       'contraband_drugs', 'contraband_weapons', 'search_conducted',\n",
            "       'search_vehicle', 'all_violation', 'speeding_only', 'county_type',\n",
            "       'sunset', 'sunrise', 'dawn', 'dusk', 'stop_time', 'light_cat',\n",
            "       'holiday'],\n",
            "      dtype='object')\n",
            "Before speed filtering:  2511664\n",
            "After speed filtering:  791271\n",
            "Index(['date', 'time', 'lat', 'lng', 'county_name', 'subject_race',\n",
            "       'subject_sex', 'violation', 'citation_issued', 'contraband_found',\n",
            "       'contraband_drugs', 'contraband_weapons', 'search_conducted',\n",
            "       'search_vehicle', 'all_violation', 'speeding_only', 'county_type',\n",
            "       'sunset', 'sunrise', 'dawn', 'dusk', 'stop_time', 'light_cat',\n",
            "       'holiday'],\n",
            "      dtype='object')\n",
            "Before speed filtering:  2368990\n",
            "After speed filtering:  734095\n",
            "Index(['date', 'time', 'lat', 'lng', 'county_name', 'subject_race',\n",
            "       'subject_sex', 'violation', 'citation_issued', 'contraband_found',\n",
            "       'contraband_drugs', 'contraband_weapons', 'search_conducted',\n",
            "       'search_vehicle', 'all_violation', 'speeding_only', 'county_type',\n",
            "       'sunset', 'sunrise', 'dawn', 'dusk', 'stop_time', 'light_cat',\n",
            "       'holiday'],\n",
            "      dtype='object')\n",
            "Before speed filtering:  2076397\n",
            "After speed filtering:  640778\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/astral/sun.py\u001b[0m in \u001b[0;36mdawn\u001b[0;34m(observer, date, depression, tzinfo)\u001b[0m\n\u001b[1;32m    734\u001b[0m         return time_of_transit(\n\u001b[0;32m--> 735\u001b[0;31m             \u001b[0mobserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSunDirection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRISING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m         ).astimezone(tzinfo)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/astral/sun.py\u001b[0m in \u001b[0;36mtime_of_transit\u001b[0;34m(observer, date, zenith, direction)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mzenith\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madjustment_for_elevation\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0madjustment_for_refraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/astral/sun.py\u001b[0m in \u001b[0;36mhour_angle\u001b[0;34m(latitude, declination, zenith, direction)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mHA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSunDirection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSETTING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: math domain error",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-98084b2a5790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdata_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrm_na_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrm_na_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'traffic_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/gdrive/MyDrive/traffic_stop/year_data_preprocessed/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.parquet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdata_write\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pyarrow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-d8aa2b49206f>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(year, keep_col, rm_na_col, violation_type)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# add lightning variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_daylight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;31m# add holiday variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'holiday'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mis_holiday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-05dc3df4ab2f>\u001b[0m in \u001b[0;36madd_daylight\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;31m# add 'sunrise', 'sunset', 'dawn', 'dusk' columns, data types are all datetime.datetime object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sunset'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msunrise_sunset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sunset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sunrise'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msunrise_sunset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sunrise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dawn'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msunrise_sunset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7550\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7551\u001b[0m         )\n\u001b[0;32m-> 7552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-05dc3df4ab2f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;31m# add 'sunrise', 'sunset', 'dawn', 'dusk' columns, data types are all datetime.datetime object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sunset'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msunrise_sunset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sunset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sunrise'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msunrise_sunset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sunrise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dawn'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msunrise_sunset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-8a4fe67ba438>\u001b[0m in \u001b[0;36msunrise_sunset\u001b[0;34m(row, info)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# use central timezone, need to change for two counties!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mcity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocationInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimezone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'US/Central'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtzinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimezone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# Get relevant info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/astral/sun.py\u001b[0m in \u001b[0;36msun\u001b[0;34m(observer, date, dawn_dusk_depression, tzinfo)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     return {\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0;34m\"dawn\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdawn_dusk_depression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtzinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m         \u001b[0;34m\"sunrise\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msunrise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtzinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;34m\"noon\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnoon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtzinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/astral/sun.py\u001b[0m in \u001b[0;36mdawn\u001b[0;34m(observer, date, depression, tzinfo)\u001b[0m\n\u001b[1;32m    739\u001b[0m             raise ValueError(\n\u001b[1;32m    740\u001b[0m                 \u001b[0;34mf\"Sun never reaches {dep} degrees below the horizon, at this location.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             ) from exc\n\u001b[0m\u001b[1;32m    742\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Sun never reaches 6.0 degrees below the horizon, at this location."
          ]
        }
      ],
      "source": [
        "for year in years:\n",
        "  data_write = preprocess(year=year,keep_col = keep_col, rm_na_col = rm_na_col)\n",
        "  file_name = 'traffic_' + str(year)\n",
        "  path = '/gdrive/MyDrive/traffic_stop/year_data_preprocessed/' + file_name + '.parquet'\n",
        "  data_write.to_parquet(path, engine='pyarrow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3yD3z00uHyN",
        "outputId": "22484f4f-6ad7-4e15-b9cd-23c8d2947ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before speed filtering:  1832072\n",
            "After speed filtering:  556284\n",
            "Index(['date', 'time', 'lat', 'lng', 'county_name', 'subject_race',\n",
            "       'subject_sex', 'violation', 'citation_issued', 'contraband_found',\n",
            "       'contraband_drugs', 'contraband_weapons', 'search_conducted',\n",
            "       'search_vehicle', 'all_violation', 'speeding_only', 'county_type',\n",
            "       'sunset', 'sunrise', 'dawn', 'dusk', 'stop_time', 'light_cat',\n",
            "       'holiday'],\n",
            "      dtype='object')\n",
            "Before speed filtering:  2197356\n",
            "After speed filtering:  625507\n",
            "Index(['date', 'time', 'lat', 'lng', 'county_name', 'subject_race',\n",
            "       'subject_sex', 'violation', 'citation_issued', 'contraband_found',\n",
            "       'contraband_drugs', 'contraband_weapons', 'search_conducted',\n",
            "       'search_vehicle', 'all_violation', 'speeding_only', 'county_type',\n",
            "       'sunset', 'sunrise', 'dawn', 'dusk', 'stop_time', 'light_cat',\n",
            "       'holiday'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "for year in list(range(2016, 2018)):\n",
        "  data_write = preprocess(year=year,keep_col = keep_col, rm_na_col = rm_na_col)\n",
        "  file_name = 'traffic_' + str(year)\n",
        "  path = '/gdrive/MyDrive/traffic_stop/year_data_preprocessed/' + file_name + '.parquet'\n",
        "  data_write.to_parquet(path, engine='pyarrow')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBgryMJrDMaM"
      },
      "source": [
        "#### ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhQKMQeLCKjG"
      },
      "outputs": [],
      "source": [
        "#rm_na_col = ['county_name','violation','subject_race','subject_sex']\n",
        "df =  pd.read_parquet('/gdrive/MyDrive/traffic_stop/year_data/traffic_2016.parquet', engine = 'pyarrow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlcbPqcoCaGS",
        "outputId": "942768da-848b-418c-a2bf-b2d7913165c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "113"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['subject_sex'].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U6-yhAmCqwU",
        "outputId": "06149215-7760-4e41-891b-362c0d9e6bd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1832207"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(df['subject_sex'].value_counts()) + 113"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WavRQ5R8Cpaj",
        "outputId": "01adf1ba-f629-42e4-8b7f-747a1e75f2a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1832207"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "traffic_stop_preprocess_0129.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}