{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from PyAstronomy import pyasl\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from pygam import LogisticGAM\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "# Automating the proess of finding the filename\n",
    "dataFolder = 'data'\n",
    "plotsFolder = 'plots'\n",
    "state = 'TX'\n",
    "policeDept = 'statewide' # 'statewide' means state patrol\n",
    "\n",
    "# Choose column names to load\n",
    "colNamesList = ['date',\n",
    "                'time',\n",
    "#                 'location',\n",
    "#                 'lat', # about 40% are nan\n",
    "#                 'lng',\n",
    "                'county_name', # just use categorical metro, micro, other for all location vars\n",
    "#                 'district',\n",
    "#                 'precinct',\n",
    "#                 'region',\n",
    "                'subject_race',\n",
    "                'subject_sex',\n",
    "#                 'officer_id_hash',\n",
    "#                 'type',\n",
    "                'violation',\n",
    "                'citation_issued',\n",
    "                'warning_issued', \n",
    "                'contraband_found',\n",
    "                'contraband_drugs',\n",
    "                'contraband_weapons',\n",
    "                'search_conducted',\n",
    "                'search_vehicle']\n",
    "                \n",
    "# Too many nans or categories\n",
    "#                 'outcome',\n",
    "#                 'search_basis',\n",
    "#                 'vehicle_color',\n",
    "#                 'vehicle_make',\n",
    "#                 'vehicle_model',\n",
    "#                 'vehicle_type',\n",
    "#                 'vehicle_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automating the creation of rowName:dtype dict\n",
    "# This throws up a lot of stupid warnings/errors right now!\n",
    "# df = pd.read_csv(csvFilepath, nrows=5, names=colNamesList)\n",
    "# dtypeDict = df.dtypes.to_dict()\n",
    "# dtypeDict\n",
    "\n",
    "dtypeDict = {'raw_row_number': 'int64', \n",
    "             'date': 'object',\n",
    "             'time': 'object',\n",
    "             'location': 'object',\n",
    "             'lat': 'float64',\n",
    "             'lng': 'float64',\n",
    "             'county_name': 'object',\n",
    "             'district': 'object',\n",
    "             'precinct': 'object',\n",
    "             'region': 'float64',\n",
    "             'subject_race': 'object',\n",
    "             'subject_sex': 'object',\n",
    "             'officer_id_hash': 'object',\n",
    "             'type': 'object',\n",
    "             'violation': 'object',\n",
    "             'citation_issued': 'bool',\n",
    "             'warning_issued': 'bool',\n",
    "             'outcome': 'object',\n",
    "             'contraband_found': 'object',\n",
    "             'contraband_drugs': 'object',\n",
    "             'contraband_weapons': 'object',\n",
    "             'search_conducted': 'object',\n",
    "             'search_vehicle': 'object',\n",
    "             'search_basis': 'object',\n",
    "             'vehicle_color': 'object',\n",
    "             'vehicle_make': 'object',\n",
    "             'vehicle_model': 'object',\n",
    "             'vehicle_type': 'object',\n",
    "             'vehicle_year': 'float64',\n",
    "             'raw_HA_RACE_SEX': 'object',\n",
    "             'raw_HA_SEARCH_PC_boolean': 'object',\n",
    "             'raw_HA_SEARCH_CONCENT_boolean': 'object',\n",
    "             'raw_HA_INCIDTO_ARREST_boolean': 'object',\n",
    "             'raw_HA_VEHICLE_INVENT_boolean': 'object'}\n",
    "\n",
    "\n",
    "        \n",
    "# search_vehicle only has False and nan\n",
    "# type is just vehicular\n",
    "# violation column is of interest - reason for stop (split by |?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading time: 237\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = utils.load_data(dataFolder, state, policeDept, dtypeDict=dtypeDict, colNames=colNamesList)\n",
    "df = utils.remove_empty_rows(df, 'subject_race')\n",
    "print('loading time: %d'%(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.remove_empty_rows(df, 'violation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16048469"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['violation'] = [s.lower() for s in df['violation']]\n",
    "df = df[df['violation'].str.contains('speed', regex=False)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('violation', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date & time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df['date']).dt.year\n",
    "df['yearfrac'] = [pyasl.decimalYear(d) for d in pd.to_datetime(df['date'])]\n",
    "df['yearfrac'] = df['yearfrac'] - df['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['minute'] = pd.to_datetime(df['time']).dt.minute\n",
    "df['hour'] = pd.to_datetime(df['time']).dt.hour\n",
    "df['time'] = df['hour'] + df['minute'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np.array(df['time']).reshape(-1,1))\n",
    "df['time'] = scaler.transform(np.array(df['time']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['hour', 'minute', 'date'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "county name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_df = pd.read_csv('2014-2018.csv')\n",
    "county_df = county_df[county_df['State']=='Texas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Micropolitan', 'Metropolitan', 'Non core'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_df = county_df.filter(items=['Metropolitan Status', 'County Name'])\n",
    "county_df['Metropolitan Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.remove_empty_rows(df, 'county_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['county_name'] = [name[:-7] for name in df['county_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(county_df.set_index('County Name'), on='county_name')\n",
    "df.drop('county_name', 1, inplace=True)\n",
    "df.rename({'Metropolitan Status':'county_type'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>subject_race</th>\n",
       "      <th>subject_sex</th>\n",
       "      <th>citation_issued</th>\n",
       "      <th>warning_issued</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>contraband_drugs</th>\n",
       "      <th>contraband_weapons</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>search_vehicle</th>\n",
       "      <th>year</th>\n",
       "      <th>yearfrac</th>\n",
       "      <th>Metropolitan Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Non core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Non core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Non core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>male</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Non core</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time subject_race subject_sex  citation_issued  warning_issued  \\\n",
       "1   0.0        white        male             True           False   \n",
       "3   0.0        white        male            False            True   \n",
       "5   0.0     hispanic        male            False            True   \n",
       "6   0.0     hispanic        male            False            True   \n",
       "8   0.0     hispanic        male             True           False   \n",
       "\n",
       "  contraband_found contraband_drugs contraband_weapons search_conducted  \\\n",
       "1               na               na                 na            FALSE   \n",
       "3               na               na                 na            FALSE   \n",
       "5               na               na                 na            FALSE   \n",
       "6               na               na                 na            FALSE   \n",
       "8               na               na                 na            FALSE   \n",
       "\n",
       "  search_vehicle  year  yearfrac Metropolitan Status  \n",
       "1          FALSE  2006       0.0            Non core  \n",
       "3          FALSE  2006       0.0        Metropolitan  \n",
       "5          FALSE  2006       0.0            Non core  \n",
       "6          FALSE  2006       0.0            Non core  \n",
       "8          FALSE  2006       0.0            Non core  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    df[col].fillna('na', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['citation_issued']).astype(int)\n",
    "\n",
    "cont_df = df.filter(items=['time', 'yearfrac', 'year'])\n",
    "cat_df = df.drop(['time', 'yearfrac', 'year', 'citation_issued'], 1)\n",
    "X_cont = np.array(cont_df)\n",
    "X_cat = np.array(cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['asian/pacific islander', 'black', 'hispanic', 'other', 'white'],\n",
       "       dtype=object),\n",
       " array(['female', 'male', 'na'], dtype=object),\n",
       " array([False, True], dtype=object),\n",
       " array(['FALSE', 'TRUE', 'na'], dtype=object),\n",
       " array(['FALSE', 'TRUE', 'na'], dtype=object),\n",
       " array(['FALSE', 'TRUE', 'na'], dtype=object),\n",
       " array(['FALSE', 'TRUE', 'na'], dtype=object),\n",
       " array(['FALSE', 'na'], dtype=object),\n",
       " array(['Metropolitan', 'Micropolitan', 'Non core', 'na'], dtype=object)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(X_cat)\n",
    "X_cat = enc.transform(X_cat)\n",
    "end = time.time()\n",
    "\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding time: 52\n"
     ]
    }
   ],
   "source": [
    "print('encoding time: %d'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def delete_rows_csr(mat, indices):\n",
    "    \"\"\"\n",
    "    Remove the rows denoted by ``indices`` form the CSR sparse matrix ``mat``.\n",
    "    \"\"\"\n",
    "    if not isinstance(mat, scipy.sparse.csr_matrix):\n",
    "        raise ValueError(\"works only for CSR format -- use .tocsr() first\")\n",
    "    indices = list(indices)\n",
    "    mask = np.ones(mat.shape[0], dtype=bool)\n",
    "    mask[indices] = False\n",
    "    return mat[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "X_cat = delete_rows_csr(X_cat.copy().T.tocsr(), [4]).T.tocsr()\n",
    "X = csr_matrix(hstack([X_cat,csr_matrix(X_cont)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13641196, 30) (13641196,) (2407271, 30) (2407271,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 714\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf = LogisticRegressionCV(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('training time: %d'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8744580753769684"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "y_train_pred = clf.predict(X_train)\n",
    "np.mean(y_train_pred == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8741716242167998"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "y_test_pred = clf.predict(X_test)\n",
    "np.mean(y_test_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_race', 'subject_sex', 'warning_issued', 'contraband_found',\n",
      "       'contraband_drugs', 'contraband_weapons', 'search_conducted',\n",
      "       'search_vehicle', 'Metropolitan Status'],\n",
      "      dtype='object')\n",
      "white [0.00373567] [1.00374265]\n",
      "asian/pacific islander [0.06004772] [1.06188721]\n",
      "black [0.38474363] [1.46923761]\n",
      "hispanic [0.57667698] [1.78011324]\n",
      "other [0.00344933] [1.00345529]\n",
      "female [-0.05817201] [0.94348765]\n",
      "male [0.06177547] [1.06372348]\n",
      "na [2.11144402e-05] [1.00002111]\n",
      "False [3.26558646] [26.19546909]\n",
      "True [-3.26196188] [0.03831316]\n",
      "FALSE [0.09191531] [1.09627198]\n",
      "TRUE [0.20706746] [1.23006555]\n",
      "na [-0.29535818] [0.74426496]\n",
      "FALSE [0.18382587] [1.20180653]\n",
      "TRUE [0.1151569] [1.12204947]\n",
      "na [-0.29535818] [0.74426496]\n",
      "FALSE [0.29189887] [1.3389676]\n",
      "TRUE [0.0070839] [1.00710905]\n",
      "na [-0.29535818] [0.74426496]\n",
      "FALSE [-0.10608813] [0.89934538]\n",
      "TRUE [0.29898277] [1.34848639]\n",
      "na [-0.18927005] [0.82756299]\n",
      "FALSE [-0.04068585] [0.9601307]\n",
      "na [0.04431044] [1.04530681]\n",
      "Metropolitan [0.26483026] [1.30320976]\n",
      "Micropolitan [-0.14580343] [0.86432759]\n",
      "Non core [-0.10431878] [0.90093805]\n",
      "na [-0.01108347] [0.98897772]\n",
      "time [0.03285134] [1.0333969]\n",
      "yearfrac [-0.03344407] [0.967109]\n",
      "year [0.00118564] [1.00118635]\n"
     ]
    }
   ],
   "source": [
    "cols = []\n",
    "for l in enc.categories_:\n",
    "    cols.extend(l)\n",
    "cols.extend(cont_df.columns)\n",
    "cols.remove('white')\n",
    "\n",
    "print(cat_df.columns)\n",
    "\n",
    "print('white', clf.intercept_, np.exp(clf.intercept_))\n",
    "for i in range(X.shape[1]):\n",
    "    print(cols[i], clf.coef_.T[i], np.exp(clf.coef_.T[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic GAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "gam = LogisticGAM().fit(X_train.todense(), y_train)\n",
    "end = time.time()\n",
    "print('gam train time: %d'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training accuracy\n",
    "y_train_pred = gam.predict(X_train.todense())\n",
    "np.mean(y_train_pred == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing accuracy\n",
    "y_test_pred = gam.predict(X_test.todense())\n",
    "np.mean(y_test_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_df.columns)\n",
    "\n",
    "print('white', gam.coef_[0])\n",
    "for i in range(X.shape[1]):\n",
    "    print(cols[i], gam.coef_.T[i+1], np.exp(gam.coef_.T[i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
